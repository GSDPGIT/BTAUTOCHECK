#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¤šAIæ¨¡åž‹å®‰å…¨åˆ†æžå™¨
Multi-AI Model Security Analyzer
æ”¯æŒ: Gemini, OpenAI, Claude, æ–‡å¿ƒä¸€è¨€, é€šä¹‰åƒé—®, æ™ºè°±GLM, DeepSeek, Kimi, è®¯é£žæ˜Ÿç«
"""

import json
import os
import sys
import requests
import time
import hashlib
import hmac
import base64
from datetime import datetime
from urllib.parse import urlencode

class AIAnalyzer:
    """AIå®‰å…¨åˆ†æžå™¨ - æ”¯æŒå¤šç§AIæ¨¡åž‹"""
    
    def __init__(self, config_file='config.json'):
        """åˆå§‹åŒ–AIåˆ†æžå™¨"""
        self.config = self.load_config(config_file)
        self.ai_config = self.config.get('ai_providers', {})
        self.primary_provider = self.ai_config.get('primary_provider', 'gemini')
        self.fallback_enabled = self.ai_config.get('fallback_enabled', True)
        
    def load_config(self, config_file):
        """åŠ è½½é…ç½®"""
        with open(config_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def analyze_code(self, code_sample, file_info=""):
        """
        ä½¿ç”¨AIåˆ†æžä»£ç å®‰å…¨æ€§
        
        Args:
            code_sample: ä»£ç æ ·æœ¬
            file_info: æ–‡ä»¶ä¿¡æ¯
            
        Returns:
            åˆ†æžç»“æžœå­—å…¸
        """
        if not self.ai_config.get('enabled', False):
            return self._static_analysis_fallback(code_sample)
        
        # æž„å»ºåˆ†æžæç¤º
        prompt = self._build_security_prompt(code_sample, file_info)
        
        # å°è¯•ä¸»è¦æä¾›å•†
        provider_config = self.ai_config.get(self.primary_provider, {})
        if provider_config.get('enabled', False):
            result = self._call_ai_provider(self.primary_provider, prompt, provider_config)
            if result:
                return result
        
        # å¦‚æžœå¯ç”¨äº†å¤‡ç”¨ï¼Œå°è¯•å…¶ä»–æä¾›å•†
        if self.fallback_enabled:
            for provider_name, provider_config in self.ai_config.items():
                if provider_name in ['enabled', 'primary_provider', 'fallback_enabled']:
                    continue
                if provider_name == self.primary_provider:
                    continue
                if provider_config.get('enabled', False):
                    print(f"ðŸ”„ åˆ‡æ¢åˆ°å¤‡ç”¨AI: {provider_name}")
                    result = self._call_ai_provider(provider_name, prompt, provider_config)
                    if result:
                        return result
        
        # æ‰€æœ‰AIéƒ½å¤±è´¥ï¼Œä½¿ç”¨é™æ€åˆ†æž
        print("âš ï¸  æ‰€æœ‰AIæä¾›å•†ä¸å¯ç”¨ï¼Œä½¿ç”¨é™æ€åˆ†æž")
        return self._static_analysis_fallback(code_sample)
    
    def _build_security_prompt(self, code_sample, file_info):
        """æž„å»ºå®‰å…¨åˆ†æžæç¤ºè¯"""
        return f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä»£ç å®‰å…¨å®¡è®¡ä¸“å®¶ã€‚è¯·åˆ†æžä»¥ä¸‹BTï¼ˆå®å¡”ï¼‰é¢æ¿ä»£ç çš„å®‰å…¨æ€§ã€‚

æ–‡ä»¶ä¿¡æ¯ï¼š{file_info}

ä»£ç å†…å®¹ï¼š
```
{code_sample[:8000]}  # é™åˆ¶é•¿åº¦
```

è¯·ä»Žä»¥ä¸‹è§’åº¦åˆ†æžï¼š
1. åŽé—¨é£Žé™©ï¼ˆè¿œç¨‹è¿žæŽ¥ã€å‘½ä»¤æ‰§è¡Œã€æ•°æ®ä¸Šä¼ ï¼‰
2. æ¶æ„ä»£ç ï¼ˆç—…æ¯’ã€æœ¨é©¬ã€æŒ–çŸ¿ç¨‹åºï¼‰
3. éšç§æ³„éœ²ï¼ˆæœªæŽˆæƒçš„æ•°æ®æ”¶é›†ï¼‰
4. å¹¿å‘Šè¿½è¸ªï¼ˆå¹¿å‘Šå±•ç¤ºã€è¡Œä¸ºè¿½è¸ªï¼‰
5. å®‰å…¨æ¼æ´žï¼ˆSQLæ³¨å…¥ã€å‘½ä»¤æ³¨å…¥ç­‰ï¼‰

è¯·ä»¥JSONæ ¼å¼è¿”å›žåˆ†æžç»“æžœï¼š
{{
    "security_score": 85,
    "risk_level": "low/medium/high",
    "findings": [
        {{"type": "åŽé—¨", "severity": "high", "description": "...", "line": 123}},
        ...
    ],
    "recommendation": "æ€»ä½“è¯„ä»·å’Œå»ºè®®",
    "safe_to_use": true/false
}}"""
    
    def _call_ai_provider(self, provider_name, prompt, provider_config):
        """è°ƒç”¨AIæä¾›å•†"""
        try:
            if provider_name == 'gemini':
                return self._call_gemini(prompt, provider_config)
            elif provider_name == 'openai':
                return self._call_openai(prompt, provider_config)
            elif provider_name == 'claude':
                return self._call_claude(prompt, provider_config)
            elif provider_name == 'qianwen':
                return self._call_qianwen(prompt, provider_config)
            elif provider_name == 'wenxin':
                return self._call_wenxin(prompt, provider_config)
            elif provider_name == 'zhipu':
                return self._call_zhipu(prompt, provider_config)
            elif provider_name == 'deepseek':
                return self._call_deepseek(prompt, provider_config)
            elif provider_name == 'kimi':
                return self._call_kimi(prompt, provider_config)
            elif provider_name == 'xunfei':
                return self._call_xunfei(prompt, provider_config)
            else:
                print(f"âŒ æœªçŸ¥çš„AIæä¾›å•†: {provider_name}")
                return None
        except Exception as e:
            print(f"âŒ {provider_name} è°ƒç”¨å¤±è´¥: {e}")
            return None
    
    def _call_gemini(self, prompt, config):
        """è°ƒç”¨Google Gemini"""
        api_key = config.get('api_key')
        model = config.get('model', 'gemini-2.0-flash-exp')
        
        url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={api_key}"
        
        payload = {
            "contents": [{
                "parts": [{"text": prompt}]
            }]
        }
        
        response = requests.post(url, json=payload, timeout=60)
        if response.status_code == 200:
            data = response.json()
            text = data['candidates'][0]['content']['parts'][0]['text']
            return self._parse_ai_response(text, 'gemini')
        else:
            print(f"âŒ Gemini APIé”™è¯¯: {response.status_code}")
            return None
    
    def _call_openai(self, prompt, config):
        """è°ƒç”¨OpenAI GPT"""
        api_key = config.get('api_key')
        model = config.get('model', 'gpt-4-turbo-preview')
        
        headers = {
            'Authorization': f'Bearer {api_key}',
            'Content-Type': 'application/json'
        }
        
        payload = {
            "model": model,
            "messages": [
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä»£ç å®‰å…¨å®¡è®¡ä¸“å®¶ã€‚"},
                {"role": "user", "content": prompt}
            ],
            "temperature": 0.3
        }
        
        response = requests.post('https://api.openai.com/v1/chat/completions', 
                               headers=headers, json=payload, timeout=60)
        if response.status_code == 200:
            data = response.json()
            text = data['choices'][0]['message']['content']
            return self._parse_ai_response(text, 'openai')
        else:
            print(f"âŒ OpenAI APIé”™è¯¯: {response.status_code}")
            return None
    
    def _call_claude(self, prompt, config):
        """è°ƒç”¨Anthropic Claude"""
        api_key = config.get('api_key')
        model = config.get('model', 'claude-3-opus-20240229')
        
        headers = {
            'x-api-key': api_key,
            'anthropic-version': '2023-06-01',
            'content-type': 'application/json'
        }
        
        payload = {
            "model": model,
            "max_tokens": 4096,
            "messages": [
                {"role": "user", "content": prompt}
            ]
        }
        
        response = requests.post('https://api.anthropic.com/v1/messages',
                               headers=headers, json=payload, timeout=60)
        if response.status_code == 200:
            data = response.json()
            text = data['content'][0]['text']
            return self._parse_ai_response(text, 'claude')
        else:
            print(f"âŒ Claude APIé”™è¯¯: {response.status_code}")
            return None
    
    def _call_qianwen(self, prompt, config):
        """è°ƒç”¨é˜¿é‡Œé€šä¹‰åƒé—®"""
        api_key = config.get('api_key')
        model = config.get('model', 'qwen-max')
        
        headers = {
            'Authorization': f'Bearer {api_key}',
            'Content-Type': 'application/json'
        }
        
        payload = {
            "model": model,
            "input": {
                "messages": [
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä»£ç å®‰å…¨å®¡è®¡ä¸“å®¶ã€‚"},
                    {"role": "user", "content": prompt}
                ]
            },
            "parameters": {
                "result_format": "message"
            }
        }
        
        response = requests.post('https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation',
                               headers=headers, json=payload, timeout=60)
        if response.status_code == 200:
            data = response.json()
            text = data['output']['choices'][0]['message']['content']
            return self._parse_ai_response(text, 'qianwen')
        else:
            print(f"âŒ é€šä¹‰åƒé—®APIé”™è¯¯: {response.status_code}")
            return None
    
    def _call_wenxin(self, prompt, config):
        """è°ƒç”¨ç™¾åº¦æ–‡å¿ƒä¸€è¨€"""
        api_key = config.get('api_key')
        secret_key = config.get('secret_key')
        
        # èŽ·å–access_token
        auth_url = f"https://aip.baidubce.com/oauth/2.0/token?grant_type=client_credentials&client_id={api_key}&client_secret={secret_key}"
        auth_response = requests.get(auth_url)
        access_token = auth_response.json().get('access_token')
        
        if not access_token:
            print("âŒ æ–‡å¿ƒä¸€è¨€èŽ·å–tokenå¤±è´¥")
            return None
        
        url = f"https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop/chat/completions_pro?access_token={access_token}"
        
        payload = {
            "messages": [
                {"role": "user", "content": prompt}
            ]
        }
        
        response = requests.post(url, json=payload, timeout=60)
        if response.status_code == 200:
            data = response.json()
            text = data.get('result', '')
            return self._parse_ai_response(text, 'wenxin')
        else:
            print(f"âŒ æ–‡å¿ƒä¸€è¨€APIé”™è¯¯: {response.status_code}")
            return None
    
    def _call_zhipu(self, prompt, config):
        """è°ƒç”¨æ™ºè°±GLM"""
        api_key = config.get('api_key')
        model = config.get('model', 'glm-4')
        
        headers = {
            'Authorization': f'Bearer {api_key}',
            'Content-Type': 'application/json'
        }
        
        payload = {
            "model": model,
            "messages": [
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä»£ç å®‰å…¨å®¡è®¡ä¸“å®¶ã€‚"},
                {"role": "user", "content": prompt}
            ]
        }
        
        response = requests.post('https://open.bigmodel.cn/api/paas/v4/chat/completions',
                               headers=headers, json=payload, timeout=60)
        if response.status_code == 200:
            data = response.json()
            text = data['choices'][0]['message']['content']
            return self._parse_ai_response(text, 'zhipu')
        else:
            print(f"âŒ æ™ºè°±GLM APIé”™è¯¯: {response.status_code}")
            return None
    
    def _call_deepseek(self, prompt, config):
        """è°ƒç”¨DeepSeek"""
        api_key = config.get('api_key')
        model = config.get('model', 'deepseek-chat')
        
        headers = {
            'Authorization': f'Bearer {api_key}',
            'Content-Type': 'application/json'
        }
        
        payload = {
            "model": model,
            "messages": [
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä»£ç å®‰å…¨å®¡è®¡ä¸“å®¶ã€‚"},
                {"role": "user", "content": prompt}
            ]
        }
        
        response = requests.post('https://api.deepseek.com/v1/chat/completions',
                               headers=headers, json=payload, timeout=60)
        if response.status_code == 200:
            data = response.json()
            text = data['choices'][0]['message']['content']
            return self._parse_ai_response(text, 'deepseek')
        else:
            print(f"âŒ DeepSeek APIé”™è¯¯: {response.status_code}")
            return None
    
    def _call_kimi(self, prompt, config):
        """è°ƒç”¨Kimi (æœˆä¹‹æš—é¢)"""
        api_key = config.get('api_key')
        model = config.get('model', 'moonshot-v1-8k')
        
        headers = {
            'Authorization': f'Bearer {api_key}',
            'Content-Type': 'application/json'
        }
        
        payload = {
            "model": model,
            "messages": [
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä»£ç å®‰å…¨å®¡è®¡ä¸“å®¶ã€‚"},
                {"role": "user", "content": prompt}
            ],
            "temperature": 0.3
        }
        
        response = requests.post('https://api.moonshot.cn/v1/chat/completions',
                               headers=headers, json=payload, timeout=60)
        if response.status_code == 200:
            data = response.json()
            text = data['choices'][0]['message']['content']
            return self._parse_ai_response(text, 'kimi')
        else:
            print(f"âŒ Kimi APIé”™è¯¯: {response.status_code}")
            return None
    
    def _call_xunfei(self, prompt, config):
        """è°ƒç”¨è®¯é£žæ˜Ÿç«ï¼ˆWebSocketæ–¹å¼ï¼Œæ­¤å¤„ç®€åŒ–ä¸ºHTTPæ¨¡æ‹Ÿï¼‰"""
        # è®¯é£žæ˜Ÿç«ä½¿ç”¨WebSocketï¼Œè¿™é‡Œæä¾›ç®€åŒ–ç‰ˆæœ¬
        print("âš ï¸  è®¯é£žæ˜Ÿç«éœ€è¦WebSocketå®žçŽ°ï¼Œå½“å‰ç‰ˆæœ¬æš‚ä¸æ”¯æŒ")
        print("   å»ºè®®ä½¿ç”¨å…¶ä»–AIæä¾›å•†")
        return None
    
    def _parse_ai_response(self, text, provider):
        """è§£æžAIå“åº”"""
        try:
            # å°è¯•ä»Žå“åº”ä¸­æå–JSON
            # AIé€šå¸¸ä¼šè¿”å›žåŒ…å«ä»£ç å—çš„markdownï¼Œéœ€è¦æå–JSONéƒ¨åˆ†
            if '```json' in text:
                json_start = text.find('```json') + 7
                json_end = text.find('```', json_start)
                json_text = text[json_start:json_end].strip()
            elif '```' in text:
                json_start = text.find('```') + 3
                json_end = text.find('```', json_start)
                json_text = text[json_start:json_end].strip()
            elif '{' in text and '}' in text:
                json_start = text.find('{')
                json_end = text.rfind('}') + 1
                json_text = text[json_start:json_end]
            else:
                json_text = text
            
            result = json.loads(json_text)
            result['ai_provider'] = provider
            result['ai_response_time'] = datetime.now().isoformat()
            return result
            
        except json.JSONDecodeError:
            # å¦‚æžœæ— æ³•è§£æžJSONï¼Œè¿”å›žåŽŸå§‹æ–‡æœ¬
            print(f"âš ï¸  {provider} è¿”å›žæ ¼å¼å¼‚å¸¸ï¼Œå°è¯•è§£æžæ–‡æœ¬...")
            return {
                'security_score': 75,
                'risk_level': 'medium',
                'findings': [],
                'recommendation': text[:500],
                'safe_to_use': True,
                'ai_provider': provider,
                'parse_failed': True
            }
    
    def _static_analysis_fallback(self, code_sample):
        """é™æ€åˆ†æžå¤‡ç”¨æ–¹æ¡ˆ"""
        # ç®€åŒ–çš„é™æ€åˆ†æž
        score = 80
        findings = []
        
        # æ£€æµ‹é«˜å±æ¨¡å¼
        dangerous_patterns = [
            ('eval(', 'åŠ¨æ€ä»£ç æ‰§è¡Œ'),
            ('exec(', 'åŠ¨æ€ä»£ç æ‰§è¡Œ'),
            ('__import__', 'åŠ¨æ€å¯¼å…¥'),
            ('os.system', 'ç³»ç»Ÿå‘½ä»¤æ‰§è¡Œ'),
            ('subprocess', 'å­è¿›ç¨‹æ‰§è¡Œ'),
        ]
        
        for pattern, desc in dangerous_patterns:
            if pattern in code_sample:
                findings.append({
                    'type': 'æ½œåœ¨é£Žé™©',
                    'severity': 'medium',
                    'description': f'å‘çŽ°{desc}: {pattern}'
                })
                score -= 5
        
        return {
            'security_score': max(score, 0),
            'risk_level': 'low' if score >= 80 else 'medium',
            'findings': findings,
            'recommendation': 'é™æ€åˆ†æžå®Œæˆï¼Œå»ºè®®ç»“åˆäººå·¥å®¡æŸ¥',
            'safe_to_use': score >= 70,
            'ai_provider': 'static_analysis',
            'is_fallback': True
        }
    
    def batch_analyze_files(self, file_list, max_files=10):
        """
        æ‰¹é‡åˆ†æžæ–‡ä»¶
        
        Args:
            file_list: æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            max_files: æœ€å¤§åˆ†æžæ–‡ä»¶æ•°
            
        Returns:
            åˆ†æžç»“æžœåˆ—è¡¨
        """
        results = []
        analyzed_count = 0
        
        print(f"ðŸ“Š æ‰¹é‡åˆ†æž {len(file_list)} ä¸ªæ–‡ä»¶ï¼ˆæœ€å¤šåˆ†æž{max_files}ä¸ªï¼‰")
        
        for filepath in file_list[:max_files]:
            if analyzed_count >= max_files:
                break
            
            try:
                with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read()
                
                if len(content) > 100:  # åªåˆ†æžæœ‰å®žè´¨å†…å®¹çš„æ–‡ä»¶
                    print(f"ðŸ” åˆ†æž: {filepath}")
                    result = self.analyze_code(content, filepath)
                    if result:
                        result['file'] = filepath
                        results.append(result)
                        analyzed_count += 1
                    
                    # é¿å…APIé™æµ
                    time.sleep(1)
                    
            except Exception as e:
                print(f"âš ï¸  æ— æ³•åˆ†æž {filepath}: {e}")
                continue
        
        print(f"âœ… å·²åˆ†æž {analyzed_count} ä¸ªæ–‡ä»¶")
        return results


def test_ai_providers():
    """æµ‹è¯•æ‰€æœ‰AIæä¾›å•†"""
    print("=" * 70)
    print("ðŸ§ª æµ‹è¯•æ‰€æœ‰AIæä¾›å•†")
    print("=" * 70)
    
    analyzer = AIAnalyzer()
    
    test_code = """
    def process_user_input(data):
        # æµ‹è¯•ä»£ç 
        result = eval(data)
        return result
    """
    
    providers = analyzer.ai_config.keys()
    for provider in providers:
        if provider in ['enabled', 'primary_provider', 'fallback_enabled']:
            continue
        
        config = analyzer.ai_config.get(provider, {})
        if config.get('enabled', False):
            print(f"\nðŸ“¡ æµ‹è¯• {provider.upper()}...")
            result = analyzer._call_ai_provider(provider, 
                                               analyzer._build_security_prompt(test_code, "test.py"),
                                               config)
            if result:
                print(f"âœ… {provider} å¯ç”¨ - è¯„åˆ†: {result.get('security_score', 'N/A')}")
            else:
                print(f"âŒ {provider} ä¸å¯ç”¨")
        else:
            print(f"âšª {provider} æœªå¯ç”¨")


if __name__ == '__main__':
    if len(sys.argv) > 1 and sys.argv[1] == 'test':
        test_ai_providers()
    else:
        print("ç”¨æ³•: python3 ai_analyzer.py test")

